{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9821f5",
   "metadata": {},
   "source": [
    "# WildBerryEye — Single-Day Analysis\n",
    "\n",
    "Change the `DATE` parameter below to the day you want to analyze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db406d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paramiko import SSHClient, AutoAddPolicy\n",
    "from scp import SCPClient\n",
    "from pathlib import Path\n",
    "\n",
    "# ─── USER PARAMETERS ──────────────────────────────────────────────────────────\n",
    "DATE = \"2025-05-30\"  # ← change this to the date you want to retrieve\n",
    "REMOTE_USER = \"decim\"\n",
    "REMOTE_HOST = \"192.168.1.138\"  # ← update if different\n",
    "REMOTE_BASE = f\"/home/{REMOTE_USER}/wildberryeye/analysis/data/{DATE}\"\n",
    "LOCAL_BASE  = Path.cwd() / \"data\" / DATE\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Ensure local folder exists\n",
    "LOCAL_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Establish SSH and SCP connection\n",
    "ssh = SSHClient()\n",
    "ssh.set_missing_host_key_policy(AutoAddPolicy())\n",
    "ssh.connect(REMOTE_HOST, username=REMOTE_USER)\n",
    "\n",
    "with SCPClient(ssh.get_transport()) as scp:\n",
    "    for subfolder in [\"motion\", \"object\"]:\n",
    "        remote_path = f\"{REMOTE_BASE}/{subfolder}/{subfolder}_{DATE}.zip\"\n",
    "        local_path  = LOCAL_BASE / subfolder\n",
    "        local_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"→ Downloading {remote_path} to {local_path}\")\n",
    "        scp.get(remote_path, local_path / f\"{subfolder}_{DATE}.zip\")\n",
    "\n",
    "ssh.close()\n",
    "print(\"All files downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ─── USER PARAMETERS ──────────────────────────────────────────────────────────\n",
    "BASE_DIR = Path.cwd() / \"data\" / DATE\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def unzip_and_display(subfolder):\n",
    "    zip_path = BASE_DIR / subfolder / f\"{subfolder}_{DATE}.zip\"\n",
    "    extract_dir = BASE_DIR / subfolder\n",
    "\n",
    "    if not zip_path.exists():\n",
    "        print(f\"ZIP not found: {zip_path}\")\n",
    "        return\n",
    "\n",
    "    # Unzip only if not already unzipped (check for any JPGs)\n",
    "    if not any(extract_dir.glob(\"*.jpg\")):\n",
    "        print(f\"→ Unzipping {zip_path.name} into {extract_dir}\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "    else:\n",
    "        print(f\"Already unzipped: {extract_dir}\")\n",
    "\n",
    "    # Display the first image\n",
    "    images = sorted(extract_dir.glob(\"*.jpg\"))\n",
    "    if images:\n",
    "        print(f\"Showing first image from {subfolder}\")\n",
    "        img = Image.open(images[0])\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{subfolder.capitalize()} – {images[0].name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No images found in {extract_dir}\")\n",
    "\n",
    "# ─── Run for both object and motion folders ───────────────────────────────────\n",
    "unzip_and_display(\"object\")\n",
    "unzip_and_display(\"motion\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb44eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Configuration\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─── USER PARAMETERS ──────────────────────────────────────────────────────────\n",
    "BIN_FREQ = \"50ms\"            \n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"Looking in:\", BASE_DIR)\n",
    "if not BASE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Data folder not found: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ada407",
   "metadata": {},
   "source": [
    "## Filename Parsing (Timestamp + Metadata)\n",
    "\n",
    "Filenames are like:\n",
    "\n",
    "object_20250514-093015-123456_wildberry01_root_CONF55_IOU65.jpg\n",
    "\n",
    "motion_20250514-093016-223344_wildberry02_root_THRESH25_AREA500.jpg\n",
    "\n",
    "We’ll pull out:\n",
    "- **timestamp** (YYYYMMDD-HHMMSS)  \n",
    "- **camera** (e.g. `wildberry01`)  \n",
    "- **user** (e.g. `root`)  \n",
    "- **any numeric params** (`CONF=55`, `IOU=65`, `THRESH=25`, `AREA=500`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(img_path: Path):\n",
    "    \"\"\"\n",
    "    Handles stems like:\n",
    "      object_20250512-093015-945726_wildberry01_...\n",
    "    where 945726 is the microsecond part.\n",
    "    \"\"\"\n",
    "    stem = img_path.stem\n",
    "    parts = stem.split('_')\n",
    "    if len(parts) < 4:\n",
    "        return None\n",
    "\n",
    "    kind   = parts[0]\n",
    "    dt_str = parts[1]           # e.g. \"20250512-093015-945726\"\n",
    "    dt_fields = dt_str.split('-')\n",
    "    if len(dt_fields) < 2:\n",
    "        return None\n",
    "    date_str, time_str = dt_fields[0], dt_fields[1]\n",
    "\n",
    "    # parse base up to seconds\n",
    "    try:\n",
    "        ts = datetime.strptime(date_str + time_str, \"%Y%m%d%H%M%S\")\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    # if there is a third part, treat it as microseconds\n",
    "    if len(dt_fields) >= 3:\n",
    "        micro = dt_fields[2]\n",
    "        # pad/truncate to 6 digits\n",
    "        micro = (micro + \"000000\")[:6]\n",
    "        ts = ts.replace(microsecond=int(micro))\n",
    "\n",
    "    camera, user = parts[2], parts[3]\n",
    "    # parse any PARAM123 bits as before...\n",
    "    params = {}\n",
    "    for p in parts[4:]:\n",
    "        m = re.match(r\"([A-Za-z]+)(\\d+)\", p)\n",
    "        if m:\n",
    "            k, v = m.groups()\n",
    "            params[k] = int(v)\n",
    "\n",
    "    rec = {\"timestamp\": ts, \"kind\": kind, \"camera\": camera, \"user\": user}\n",
    "    rec.update(params)\n",
    "    return rec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849da0a6",
   "metadata": {},
   "source": [
    "## Load All Records for the Day\n",
    "\n",
    "Build a single DataFrame with one row per image, including its metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a493d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather Records\n",
    "\n",
    "records = []\n",
    "for kind in (\"object\", \"motion\"):\n",
    "    folder = BASE_DIR / kind\n",
    "    if not folder.is_dir():\n",
    "        continue\n",
    "    for img in sorted(folder.iterdir()):\n",
    "        if img.suffix.lower() not in (\".jpg\", \".jpeg\"):\n",
    "            continue\n",
    "        meta = parse_filename(img)\n",
    "        if meta:\n",
    "            records.append(meta)\n",
    "\n",
    "if not records:\n",
    "    raise RuntimeError(\"No valid records found—check filenames & folders.\")\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())\n",
    "print(df.kind.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee0b70",
   "metadata": {},
   "source": [
    "## Bin Counts Resolution\n",
    "\n",
    "Convert timestamps to Series, floor to seconds, then count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floor to bins\n",
    "df[\"ts_floor\"] = pd.to_datetime(df[\"timestamp\"]).dt.floor(freq=BIN_FREQ)\n",
    "\n",
    "# count per‐bin\n",
    "obj_counts = df[df.kind==\"object\"].groupby(\"ts_floor\").size()\n",
    "mot_counts = df[df.kind==\"motion\"].groupby(\"ts_floor\").size()\n",
    "\n",
    "# full index with steps\n",
    "full_idx = pd.date_range(\n",
    "    start=df.ts_floor.min(),\n",
    "    end  =df.ts_floor.max(),\n",
    "    freq =BIN_FREQ)\n",
    "\n",
    "obj_full = obj_counts.reindex(full_idx, fill_value=0)\n",
    "mot_full = mot_counts.reindex(full_idx, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd438f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object-Only Plot\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(obj_full.index, obj_full.values,\n",
    "         marker=\"o\", linestyle=\"-\", label=\"Object\")\n",
    "plt.title(f\"{DATE} — Object\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Detections/sec\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, ls=\"--\", lw=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion-Only Plot\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(mot_full.index, mot_full.values,\n",
    "         marker=\"x\", linestyle=\"-\", color=\"orange\", label=\"Motion\")\n",
    "plt.title(f\"{DATE} — Motion\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Detections/sec\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, ls=\"--\", lw=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf03f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay Object & Motion\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(obj_full.index, obj_full.values,\n",
    "         marker=\"o\", linestyle=\"-\", label=\"Object\")\n",
    "plt.plot(mot_full.index, mot_full.values,\n",
    "         marker=\"x\", linestyle=\"-\", color=\"orange\", label=\"Motion\")\n",
    "plt.title(f\"{DATE} — Object & Motion (1 s bins)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Detections/sec\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, ls=\"--\", lw=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54feb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunable Cluster‐based Event Detection\n",
    "\n",
    "# ─── TUNING PARAMETERS ──────────────────────────────────────────────────────────\n",
    "DET_THRESH = 1    # bins with <2 detections/sec are considered inactive\n",
    "GAP_SEC    = 60   # seconds of inactivity that break events\n",
    "MIN_COUNT  = 5    # an event must contain ≥5 total detections\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# 1) Build a list of “active” seconds above threshold\n",
    "mask = obj_full >= DET_THRESH\n",
    "det_times = obj_full.index[mask]\n",
    "\n",
    "# 2) Cluster those times into events by gap threshold\n",
    "def detect_events_by_gap(times, gap_sec):\n",
    "    events = []\n",
    "    if len(times) == 0:\n",
    "        return events\n",
    "    start = times[0]\n",
    "    prev  = times[0]\n",
    "    for curr in times[1:]:\n",
    "        if (curr - prev).total_seconds() > gap_sec:\n",
    "            events.append((start, prev))\n",
    "            start = curr\n",
    "        prev = curr\n",
    "    events.append((start, prev))\n",
    "    return events\n",
    "\n",
    "raw_events = detect_events_by_gap(det_times, GAP_SEC)\n",
    "\n",
    "# 3) Filter by total count within each event\n",
    "events = []\n",
    "for s, e in raw_events:\n",
    "    total = obj_full[s:e].sum()\n",
    "    if total >= MIN_COUNT:\n",
    "        events.append((s, e))\n",
    "\n",
    "print(f\"Found {len(events)} events \"\n",
    "      f\"(DET_THRESH={DET_THRESH}, GAP_SEC={GAP_SEC}, MIN_COUNT={MIN_COUNT}):\")\n",
    "for i, (s, e) in enumerate(events, 1):\n",
    "    print(f\"  Event {i}: {s} → {e}  (total={obj_full[s:e].sum()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f433ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay Object & Motion with Detected Events\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(obj_full.index, obj_full.values,\n",
    "         marker=\"o\", linestyle=\"-\", label=\"Object\")\n",
    "plt.plot(mot_full.index, mot_full.values,\n",
    "         marker=\"x\", linestyle=\"-\", color=\"orange\", label=\"Motion\")\n",
    "\n",
    "for s,e in events:\n",
    "    plt.axvline(s, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "    plt.axvline(e, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "plt.title(f\"{DATE} — Events (gap={GAP_SEC}s) detected\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Detections/sec\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, ls=\"--\", lw=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Each Event Independently\n",
    "\n",
    "for i, (start, end) in enumerate(events, 1):\n",
    "    # Slice out just this event’s window\n",
    "    obj_slice = obj_full[start:end]\n",
    "    mot_slice = mot_full[start:end]\n",
    "\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.plot(obj_slice.index, obj_slice.values,\n",
    "             marker=\"o\", linestyle=\"-\", label=\"Object\")\n",
    "    plt.plot(mot_slice.index, mot_slice.values,\n",
    "             marker=\"x\", linestyle=\"-\", color=\"orange\", label=\"Motion\")\n",
    "\n",
    "    plt.title(f\"Event {i}: {start.strftime('%H:%M:%S')} → {end.strftime('%H:%M:%S')}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Detections/sec\")\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, ls=\"--\", lw=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Cross-Corr on All Events\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1) Build concatenated arrays of object and motion counts, only during events\n",
    "obj_ev = []\n",
    "mot_ev = []\n",
    "for start, end in events:\n",
    "    rng = pd.date_range(start, end, freq=\"S\")\n",
    "    obj_ev.append(obj_full.reindex(rng, fill_value=0).values)\n",
    "    mot_ev.append(mot_full.reindex(rng, fill_value=0).values)\n",
    "\n",
    "# flatten into one long sequence\n",
    "obj_seq = np.concatenate(obj_ev)\n",
    "mot_seq = np.concatenate(mot_ev)\n",
    "\n",
    "# 2) subtract means and correlate\n",
    "obj_c = obj_seq - obj_seq.mean()\n",
    "mot_c = mot_seq - mot_seq.mean()\n",
    "xc_full = np.correlate(obj_c, mot_c, mode=\"full\")\n",
    "\n",
    "# 3) build lag axis in seconds\n",
    "lags = np.arange(-len(obj_seq)+1, len(obj_seq))\n",
    "\n",
    "# 4) plot a reasonable window around zero (e.g. ±30 s)\n",
    "win = 30\n",
    "mask = (lags >= -win) & (lags <= win)\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(lags[mask], xc_full[mask])\n",
    "plt.title(\"Global Cross-Correlation Over All Events\")\n",
    "plt.xlabel(\"Lag (s)\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.grid(True, ls=\"--\", lw=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build & show combined side-by-side GIF per event\n",
    "\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPyImage, display\n",
    "\n",
    "OBJ_DIR = Path.cwd() / \"data\" / DATE / \"object\"\n",
    "MOT_DIR = Path.cwd() / \"data\" / DATE / \"motion\"\n",
    "OUT_DIR = Path.cwd() / \"data\" / DATE\n",
    "\n",
    "MAX_FRAMES     = 20\n",
    "FRAME_DURATION = 0.2\n",
    "\n",
    "def equalize_list(files, target_len):\n",
    "    n = len(files)\n",
    "    if n >= target_len:\n",
    "        return [files[int(round(i*(n-1)/(target_len-1)))] for i in range(target_len)]\n",
    "    else:\n",
    "        reps = target_len // n\n",
    "        rem  = target_len % n\n",
    "        return files*reps + files[:rem]\n",
    "\n",
    "for i, (start, end) in enumerate(events, 1):\n",
    "    # collect files...\n",
    "    obj_files = []\n",
    "    for p in sorted(OBJ_DIR.iterdir()):\n",
    "        if p.suffix.lower() in (\".jpg\",\"jpeg\"):\n",
    "            meta = parse_filename(p)\n",
    "            if meta and start <= meta[\"timestamp\"] <= end:\n",
    "                obj_files.append(p)\n",
    "\n",
    "    mot_files = []\n",
    "    for p in sorted(MOT_DIR.iterdir()):\n",
    "        if p.suffix.lower() in (\".jpg\",\"jpeg\"):\n",
    "            meta = parse_filename(p)\n",
    "            if meta and start <= meta[\"timestamp\"] <= end:\n",
    "                mot_files.append(p)\n",
    "\n",
    "    if not obj_files or not mot_files:\n",
    "        continue\n",
    "\n",
    "    raw_max = max(len(obj_files), len(mot_files))\n",
    "    target  = raw_max if raw_max <= MAX_FRAMES else MAX_FRAMES\n",
    "\n",
    "    obj_eq = equalize_list(obj_files, target)\n",
    "    mot_eq = equalize_list(mot_files, target)\n",
    "\n",
    "    # build combined frames\n",
    "    combined = []\n",
    "    for of, mf in zip(obj_eq, mot_eq):\n",
    "        im_o = Image.open(of)\n",
    "        im_m = Image.open(mf)\n",
    "        w1,h1 = im_o.size\n",
    "        w2,h2 = im_m.size\n",
    "        H = max(h1,h2)\n",
    "        canvas = Image.new(\"RGB\", (w1+w2, H))\n",
    "        canvas.paste(im_o, (0,0))\n",
    "        canvas.paste(im_m, (w1,0))\n",
    "        combined.append(canvas)\n",
    "\n",
    "    # save GIF into the date folder\n",
    "    out_gif = OUT_DIR / f\"event_{i:02d}_combined.gif\"\n",
    "    combined[0].save(\n",
    "        out_gif,\n",
    "        format=\"GIF\",\n",
    "        save_all=True,\n",
    "        append_images=combined[1:],\n",
    "        duration=int(FRAME_DURATION*1000),\n",
    "        loop=0\n",
    "    )\n",
    "\n",
    "    # display inline\n",
    "    print(f\"Event {i}: {start.time()} → {end.time()}\")\n",
    "    display(IPyImage(filename=str(out_gif)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
